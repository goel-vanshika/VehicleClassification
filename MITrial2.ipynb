{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qiyU4lXRloOOu0ufw_U2SLC4ly1mRCp4",
      "authorship_tag": "ABX9TyOP9yFL+OWI5VCcn2D+KcF/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goel-vanshika/VehicleClassification/blob/main/MITrial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9HZ8W0AMKIcF"
      },
      "outputs": [],
      "source": [
        "from __future__ import division, print_function, absolute_import\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflearn\n",
        "!pip install tensorflow\n",
        "!pip install pyyaml h5py"
      ],
      "metadata": {
        "id": "SmNlgAsRK5zF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ea4405-72ac-4a56-826b-ef1da706e611"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=2c88416fcf878c4be8695cb7b659b15d4f2853abe282136991782dec1c49f100\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/14/2e/1d8e28cc47a5a931a2fb82438c9e37ef9246cc6a3774520271\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required libraries"
      ],
      "metadata": {
        "id": "Jc3mlbJ1Y8te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M6zJ-V1QzgC",
        "outputId": "01e0b2ec-651b-43b0-fddf-4552a1354509"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tflearn\n",
        "\n",
        "from tflearn.data_utils import shuffle, to_categorical\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.estimator import regression\n",
        "from tflearn.data_preprocessing import ImagePreprocessing\n",
        "from tflearn.data_augmentation import ImageAugmentation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.framework import ops"
      ],
      "metadata": {
        "id": "drnYUuxvKRE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f448a636-dd28-4803-c42d-9d64b6209d85"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset"
      ],
      "metadata": {
        "id": "aL67qLJoZBnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading test images\n",
        "from tflearn.data_utils import image_preloader\n",
        "import numpy as np\n",
        "# Loading path/class_id image file:\n",
        "dataset_file = '/content/drive/MyDrive/MI/training/dataset.txt'"
      ],
      "metadata": {
        "id": "71fQ3yWrKSo4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the dataset to an array and splitting the dataset into training and testing"
      ],
      "metadata": {
        "id": "_rBkGqu9ZGVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = image_preloader(dataset_file, image_shape=(100, 100), mode='file',\n",
        "                       categorical_labels=True, normalize=True,\n",
        "                       files_extension=['.jpg', '.png'], filter_channel=True)\n",
        "image = np.array(image)\n",
        "label = np.array(label)\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(image,label,test_size=0.2)"
      ],
      "metadata": {
        "id": "D60uyUEuKUcO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Pre-processing and Image Augmentation"
      ],
      "metadata": {
        "id": "oW53kvPFZO-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Real-time data preprocessing\n",
        "img_prep = ImagePreprocessing()\n",
        "img_prep.add_featurewise_zero_center()\n",
        "img_prep.add_featurewise_stdnorm()\n"
      ],
      "metadata": {
        "id": "ioC6Qq5_KU3o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Real-time data augmentation\n",
        "img_aug = ImageAugmentation()\n",
        "img_aug.add_random_flip_leftright()\n",
        "img_aug.add_random_rotation(max_angle=25.)"
      ],
      "metadata": {
        "id": "tnt1cSfOKWI6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the CNN network"
      ],
      "metadata": {
        "id": "sGHwxjVdZUIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional network building\n",
        "network = input_data(shape=[None, 100, 100, 3],\n",
        "                     data_preprocessing=img_prep,\n",
        "                     data_augmentation=img_aug)\n",
        "network = conv_2d(network, 64, 3, activation='relu')\n",
        "network = max_pool_2d(network, 2)\n",
        "network = conv_2d(network, 32, 3, activation='relu')\n",
        "network = max_pool_2d(network, 2)\n",
        "network = conv_2d(network, 32, 3, activation='relu')\n",
        "network = max_pool_2d(network, 2)\n",
        "network = fully_connected(network, 256, activation='relu')\n",
        "network = dropout(network, 0.75)\n",
        "network = fully_connected(network, 256, activation='relu')\n",
        "network = dropout(network, 0.75)\n",
        "network = fully_connected(network, 4, activation='softmax')\n",
        "network = regression(network, optimizer='adam',loss='categorical_crossentropy',learning_rate=0.001)\n"
      ],
      "metadata": {
        "id": "Z7huZ5arKX3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e34a4d33-337f-437c-a997-5483223522eb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tflearn/initializations.py:110: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:561: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building and training the model"
      ],
      "metadata": {
        "id": "u07oHIDCZcob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training using classifier\n",
        "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, n_epoch=50, shuffle=True, validation_set=(X_test, y_test), show_metric=True, batch_size=64, run_id='vehicleDetection')\n",
        "model.save('/content/drive/MyDrive/MI/training/saved_model3/my_model9') "
      ],
      "metadata": {
        "id": "QoSfkBZqKZSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70d7897-d72f-4db2-d39d-7c1314e51340"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Step: 3599  | total loss: \u001b[1m\u001b[32m0.07213\u001b[0m\u001b[0m | time: 98.783s\n",
            "| Adam | epoch: 050 | loss: 0.07213 - acc: 0.9744 -- iter: 4544/4552\n",
            "Training Step: 3600  | total loss: \u001b[1m\u001b[32m0.07547\u001b[0m\u001b[0m | time: 105.051s\n",
            "| Adam | epoch: 050 | loss: 0.07547 - acc: 0.9723 | val_loss: 0.47471 - val_acc: 0.8999 -- iter: 4552/4552\n",
            "--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original labels of each image in testing set"
      ],
      "metadata": {
        "id": "g5M3I4NoZf2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y=y_test.tolist()\n",
        "og=[]\n",
        "for j in y:\n",
        "  m=max(j)\n",
        "  og.append(j.index(m))\n",
        "\n",
        "print(og)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0Dqq4nbAm8D",
        "outputId": "894e5e47-66c6-4fe7-abd3-a32d6850f403"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3, 1, 1, 1, 1, 2, 0, 1, 2, 1, 2, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 2, 3, 1, 1, 2, 3, 3, 1, 1, 1, 2, 1, 0, 0, 1, 1, 0, 2, 1, 0, 0, 1, 1, 1, 2, 1, 1, 3, 1, 1, 2, 1, 3, 2, 0, 1, 2, 0, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 1, 1, 2, 3, 0, 1, 2, 3, 1, 1, 2, 2, 3, 1, 2, 1, 3, 1, 1, 3, 1, 2, 0, 2, 1, 2, 1, 2, 1, 3, 0, 1, 1, 1, 2, 0, 1, 2, 1, 2, 1, 2, 1, 2, 0, 3, 1, 1, 2, 0, 1, 1, 3, 2, 1, 3, 2, 0, 0, 1, 3, 0, 2, 1, 2, 3, 2, 2, 1, 3, 1, 1, 2, 1, 3, 1, 1, 1, 3, 2, 1, 1, 1, 0, 3, 1, 3, 2, 2, 3, 1, 0, 2, 1, 1, 1, 0, 0, 2, 2, 2, 3, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 3, 1, 1, 0, 2, 1, 0, 0, 1, 1, 2, 2, 2, 3, 2, 1, 1, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 3, 1, 0, 1, 2, 1, 1, 0, 3, 1, 2, 2, 1, 2, 1, 1, 3, 0, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 2, 1, 1, 2, 1, 0, 1, 3, 2, 1, 0, 1, 2, 1, 1, 2, 3, 3, 1, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 3, 2, 1, 2, 1, 0, 3, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 3, 2, 2, 0, 1, 2, 0, 2, 1, 1, 2, 2, 0, 1, 3, 2, 1, 1, 2, 2, 1, 3, 1, 1, 2, 0, 3, 1, 2, 1, 1, 0, 3, 1, 1, 2, 2, 1, 2, 3, 1, 1, 0, 0, 3, 1, 3, 1, 1, 1, 2, 0, 1, 0, 3, 1, 0, 2, 2, 1, 0, 3, 1, 2, 1, 2, 2, 3, 0, 1, 1, 1, 2, 1, 1, 2, 1, 3, 0, 2, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 2, 1, 2, 0, 2, 2, 3, 2, 0, 1, 1, 2, 1, 0, 1, 1, 1, 0, 3, 0, 2, 3, 2, 0, 0, 0, 1, 0, 2, 2, 2, 2, 1, 2, 2, 0, 1, 2, 1, 2, 1, 3, 0, 0, 1, 0, 1, 2, 2, 0, 2, 2, 1, 1, 1, 2, 1, 1, 3, 1, 2, 1, 0, 1, 1, 2, 1, 2, 1, 0, 1, 1, 1, 1, 2, 3, 0, 1, 0, 3, 1, 1, 0, 1, 1, 1, 0, 1, 2, 1, 1, 3, 2, 2, 1, 1, 2, 1, 1, 1, 1, 0, 2, 1, 0, 2, 1, 0, 0, 1, 1, 2, 0, 1, 2, 3, 2, 1, 2, 0, 0, 2, 1, 2, 1, 3, 2, 0, 2, 0, 0, 3, 1, 2, 0, 2, 1, 2, 2, 2, 1, 2, 1, 0, 2, 2, 2, 1, 3, 2, 3, 0, 3, 2, 2, 1, 2, 1, 1, 1, 0, 0, 1, 1, 3, 1, 0, 2, 1, 2, 0, 0, 0, 1, 1, 1, 1, 2, 0, 0, 0, 0, 1, 3, 1, 1, 2, 1, 1, 1, 0, 2, 2, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 3, 1, 1, 2, 3, 1, 3, 1, 2, 2, 1, 0, 2, 0, 2, 1, 2, 1, 0, 1, 0, 3, 3, 2, 0, 0, 1, 1, 1, 1, 1, 1, 3, 1, 2, 2, 2, 1, 2, 1, 3, 2, 1, 1, 1, 2, 2, 2, 1, 3, 1, 0, 3, 3, 3, 1, 2, 1, 0, 2, 3, 0, 1, 0, 0, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 3, 2, 1, 0, 0, 2, 2, 1, 1, 1, 1, 0, 1, 0, 1, 3, 1, 1, 2, 1, 0, 1, 2, 2, 1, 1, 2, 2, 1, 1, 0, 1, 1, 2, 1, 1, 1, 2, 3, 2, 2, 1, 3, 3, 3, 2, 0, 1, 2, 2, 2, 0, 2, 1, 2, 2, 1, 0, 0, 3, 2, 2, 1, 2, 2, 3, 1, 2, 1, 1, 1, 1, 3, 0, 0, 1, 1, 0, 0, 1, 0, 1, 2, 0, 0, 3, 1, 1, 3, 1, 2, 0, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 3, 2, 3, 1, 1, 2, 1, 3, 2, 1, 0, 3, 1, 3, 3, 1, 2, 1, 1, 1, 3, 1, 1, 0, 0, 1, 3, 1, 0, 1, 1, 1, 1, 3, 2, 3, 1, 1, 3, 1, 2, 1, 1, 1, 3, 1, 1, 3, 2, 3, 1, 2, 0, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 1, 3, 1, 3, 0, 0, 2, 2, 3, 2, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 2, 0, 1, 2, 1, 1, 0, 1, 2, 1, 1, 1, 2, 1, 0, 3, 1, 3, 0, 3, 2, 2, 3, 2, 1, 1, 1, 2, 2, 3, 0, 1, 1, 1, 1, 2, 0, 1, 2, 0, 1, 2, 1, 3, 2, 0, 0, 1, 2, 1, 2, 0, 1, 1, 2, 2, 0, 1, 2, 3, 0, 1, 0, 1, 2, 3, 0, 0, 0, 2, 1, 3, 1, 0, 0, 3, 2, 1, 1, 1, 0, 2, 3, 3, 2, 2, 2, 1, 2, 1, 3, 0, 3, 2, 1, 0, 1, 1, 1, 1, 3, 1, 1, 1, 3, 2, 3, 1, 1, 3, 0, 2, 0, 1, 2, 2, 0, 0, 3, 0, 1, 3, 0, 1, 1, 1, 0, 2, 0, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 0, 1, 2, 1, 1, 1, 0, 1, 1, 1, 3, 2, 3, 3, 1, 1, 1, 3, 2, 1, 3, 1, 1, 1, 1, 2, 3, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 1, 2, 3, 2, 3, 1, 0, 0, 1, 1, 2, 1, 3, 1, 1, 0, 1, 2, 1, 0, 0, 1, 1, 1, 1, 3, 0, 1, 2, 0, 1, 3, 1, 0, 1, 3, 2, 3, 1, 1, 0, 3, 1, 1, 3, 3, 1, 1, 1, 3, 2, 0, 3, 1, 2, 1, 3, 2, 3, 3, 1, 1, 0, 0, 1, 3, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 3, 0, 3, 1, 2, 1, 2, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 3, 0, 1, 3, 1, 1, 3, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicted labels of each image in testing set"
      ],
      "metadata": {
        "id": "oHn0TMNhZmLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred=model.predict(X_test)\n",
        "x=pred.tolist()\n",
        "labels=[]\n",
        "for i in x:\n",
        "  m=max(i)\n",
        "  labels.append(i.index(m))\n",
        "\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aakp3V11_qar",
        "outputId": "dd65256b-de54-446a-ec55-935e53552a8a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 2, 1, 1, 2, 0, 1, 2, 1, 2, 1, 2, 0, 1, 1, 0, 1, 1, 2, 1, 1, 2, 2, 1, 2, 0, 1, 1, 2, 3, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 2, 1, 0, 0, 1, 1, 1, 2, 1, 1, 3, 1, 1, 2, 1, 1, 2, 0, 1, 2, 0, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 1, 2, 2, 3, 0, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 0, 1, 1, 2, 0, 2, 0, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 2, 1, 2, 1, 2, 0, 1, 0, 1, 2, 0, 2, 2, 1, 2, 1, 1, 2, 0, 0, 1, 1, 0, 2, 1, 2, 1, 2, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 0, 3, 1, 2, 2, 2, 1, 1, 0, 2, 1, 1, 1, 0, 0, 2, 0, 2, 1, 0, 1, 2, 0, 0, 0, 1, 2, 2, 2, 1, 2, 0, 0, 2, 1, 0, 0, 2, 1, 2, 2, 2, 3, 2, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 0, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 2, 1, 2, 2, 1, 0, 2, 1, 2, 1, 0, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 0, 1, 2, 2, 2, 0, 2, 0, 2, 1, 1, 1, 2, 0, 1, 3, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 0, 0, 3, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 2, 0, 2, 1, 2, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 1, 2, 2, 1, 1, 2, 1, 1, 0, 2, 1, 1, 2, 0, 1, 0, 1, 2, 0, 1, 1, 1, 2, 1, 2, 0, 2, 2, 1, 2, 0, 2, 1, 2, 1, 0, 1, 2, 1, 0, 1, 0, 2, 1, 2, 0, 0, 0, 1, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 0, 0, 0, 1, 0, 2, 2, 2, 0, 2, 2, 1, 1, 1, 2, 1, 1, 2, 0, 2, 1, 0, 1, 0, 2, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 0, 0, 0, 1, 0, 2, 2, 2, 0, 1, 2, 2, 0, 1, 2, 0, 1, 1, 1, 1, 2, 1, 0, 2, 1, 0, 0, 1, 1, 2, 0, 2, 2, 1, 2, 1, 2, 0, 0, 2, 1, 2, 1, 1, 2, 0, 1, 0, 0, 2, 1, 2, 0, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 0, 1, 2, 2, 1, 2, 1, 2, 1, 0, 0, 1, 2, 2, 1, 0, 2, 1, 2, 0, 0, 0, 1, 1, 2, 1, 2, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 1, 1, 0, 2, 2, 0, 1, 0, 1, 0, 1, 2, 1, 0, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 0, 1, 0, 2, 1, 2, 1, 0, 1, 0, 3, 1, 2, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 0, 1, 1, 1, 1, 2, 2, 0, 2, 1, 2, 0, 0, 1, 1, 0, 1, 0, 0, 2, 1, 1, 1, 2, 1, 2, 2, 2, 0, 2, 2, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 2, 2, 1, 0, 2, 1, 1, 1, 0, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 0, 1, 3, 1, 2, 0, 1, 2, 2, 2, 0, 2, 1, 2, 2, 1, 0, 0, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 2, 0, 0, 1, 1, 1, 1, 0, 2, 0, 2, 1, 2, 2, 2, 1, 2, 2, 0, 0, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 0, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 2, 0, 2, 1, 3, 1, 1, 1, 2, 1, 1, 0, 1, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 2, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 3, 2, 1, 1, 2, 0, 1, 2, 1, 0, 0, 1, 2, 1, 2, 2, 2, 1, 0, 1, 1, 3, 1, 0, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 2, 0, 1, 2, 1, 0, 2, 0, 0, 1, 2, 1, 2, 0, 1, 1, 2, 2, 0, 1, 2, 1, 0, 1, 0, 2, 2, 3, 0, 0, 0, 1, 1, 1, 1, 0, 0, 2, 2, 2, 1, 1, 0, 2, 1, 1, 2, 2, 2, 1, 2, 1, 3, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 0, 2, 0, 1, 2, 2, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 2, 2, 1, 0, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 0, 1, 2, 1, 2, 0, 0, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 2, 3, 2, 2, 1, 1, 1, 0, 1, 0, 0, 0, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 2, 1, 1, 0, 1, 2, 1, 2, 1, 2, 0, 1, 1, 1, 2, 1, 0, 1, 2, 0, 1, 1, 1, 0, 1, 3, 2, 3, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 3, 2, 2, 3, 1, 2, 0, 0, 1, 1, 0, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 3, 0, 2, 1, 2, 2, 2, 1, 1, 0, 0, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0 - Bus\n",
        "1 - Car\n",
        "2 - Motorcycle\n",
        "3 - non-vehicles"
      ],
      "metadata": {
        "id": "alkTA_9eZtAn"
      }
    }
  ]
}